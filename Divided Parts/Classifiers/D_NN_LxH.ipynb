{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../../train.csv\")\n",
    "X = df[\"Text\"].values\n",
    "y = df[\"Category\"].values\n",
    "m = 0.9 #proportion of data for training vs validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=m, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d1cec",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae98f0",
   "metadata": {},
   "source": [
    "(d) NN. Consider a neural network with the following hyperparameters: the initial weights\n",
    "uniformly drawn in range [0,0.1] with learning rate 0.01.\n",
    "\n",
    "    ● Train a single hidden layer neural network using the hyperparameters on the training dataset, except for the number of hidden units (x) which should vary among 5, 20, and 40. Run the optimization for 100 epochs each time. Namely, the input layer consists of n features x = [x1, ..., xn]^T , the hidden layer has x nodes z = [z1, ..., zx]^T , and the output layer is a probability distribution y = [y1, y2]^T over two classes.\n",
    "\n",
    "    ● Plot the average training cross-entropy loss as shown below on the y-axis versus the number of hidden units on the x-axis. Explain the effect of numbers of hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "257ba117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector vocabulary - None\n",
      "\n",
      "features\n",
      " ['00' '000' '000th' ... 'zooms' 'zooropa' 'zorro']\n",
      "\n",
      "vector shape: (428, 13518)\n",
      "\n",
      "article vector\n",
      " [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[9.29316655e-01 7.06833448e-02]\n",
      " [6.82013361e-05 9.99931799e-01]\n",
      " [1.69985445e-06 9.99998300e-01]\n",
      " [9.99900199e-01 9.98011571e-05]\n",
      " [9.99860993e-01 1.39007386e-04]\n",
      " [9.98570220e-01 1.42978017e-03]\n",
      " [9.99224817e-01 7.75183122e-04]\n",
      " [2.05412480e-04 9.99794588e-01]\n",
      " [9.92182057e-01 7.81794272e-03]\n",
      " [9.98990223e-01 1.00977652e-03]\n",
      " [9.99238086e-01 7.61913717e-04]\n",
      " [9.18909759e-04 9.99081090e-01]\n",
      " [9.89303163e-01 1.06968367e-02]\n",
      " [9.99161385e-01 8.38614591e-04]\n",
      " [9.99994259e-01 5.74055034e-06]\n",
      " [9.98147739e-01 1.85226072e-03]\n",
      " [9.53560590e-01 4.64394103e-02]\n",
      " [9.99654076e-01 3.45923521e-04]\n",
      " [1.23914681e-02 9.87608532e-01]\n",
      " [3.44224220e-06 9.99996558e-01]\n",
      " [9.99832910e-01 1.67090377e-04]\n",
      " [9.99779692e-01 2.20307943e-04]\n",
      " [5.97496698e-04 9.99402503e-01]\n",
      " [9.88732324e-01 1.12676761e-02]\n",
      " [2.10468816e-03 9.97895312e-01]\n",
      " [9.97890257e-01 2.10974278e-03]\n",
      " [6.25519041e-03 9.93744810e-01]\n",
      " [6.57543023e-01 3.42456977e-01]\n",
      " [9.98493996e-01 1.50600448e-03]\n",
      " [2.56916407e-04 9.99743084e-01]\n",
      " [9.95996613e-01 4.00338743e-03]\n",
      " [1.65579678e-02 9.83442032e-01]\n",
      " [6.07342083e-04 9.99392658e-01]\n",
      " [1.02953946e-04 9.99897046e-01]\n",
      " [9.77719023e-01 2.22809768e-02]\n",
      " [6.25519041e-03 9.93744810e-01]\n",
      " [9.89137136e-01 1.08628638e-02]\n",
      " [3.70523572e-04 9.99629476e-01]\n",
      " [4.58277782e-03 9.95417222e-01]\n",
      " [9.60506128e-03 9.90394939e-01]\n",
      " [2.53184064e-06 9.99997468e-01]\n",
      " [9.99959230e-01 4.07700369e-05]\n",
      " [9.99994662e-01 5.33759439e-06]\n",
      " [8.77669357e-07 9.99999122e-01]\n",
      " [9.92450579e-01 7.54942139e-03]\n",
      " [9.75928730e-01 2.40712697e-02]\n",
      " [4.96023227e-01 5.03976773e-01]\n",
      " [9.99090999e-01 9.09000623e-04]\n",
      " [9.99342279e-01 6.57720685e-04]\n",
      " [1.48781916e-02 9.85121808e-01]\n",
      " [7.31913865e-02 9.26808613e-01]\n",
      " [9.78815979e-01 2.11840211e-02]\n",
      " [9.99898285e-01 1.01715145e-04]\n",
      " [9.98358884e-01 1.64111611e-03]\n",
      " [9.90486875e-01 9.51312467e-03]\n",
      " [5.50101980e-07 9.99999450e-01]\n",
      " [9.92628971e-01 7.37102888e-03]\n",
      " [3.44358393e-06 9.99996556e-01]\n",
      " [1.41823722e-06 9.99998582e-01]\n",
      " [5.46728432e-05 9.99945327e-01]\n",
      " [1.04354985e-04 9.99895645e-01]\n",
      " [5.53098469e-06 9.99994469e-01]\n",
      " [8.37487050e-01 1.62512950e-01]\n",
      " [5.15483669e-04 9.99484516e-01]\n",
      " [7.99824774e-01 2.00175226e-01]\n",
      " [9.92948071e-01 7.05192892e-03]\n",
      " [1.89215835e-07 9.99999811e-01]\n",
      " [9.90991403e-01 9.00859708e-03]\n",
      " [9.98471329e-01 1.52867150e-03]\n",
      " [1.69985445e-06 9.99998300e-01]\n",
      " [9.99258117e-01 7.41883161e-04]\n",
      " [9.99999842e-01 1.57543094e-07]\n",
      " [3.46576854e-03 9.96534231e-01]\n",
      " [9.95348841e-01 4.65115920e-03]\n",
      " [9.88097171e-01 1.19028288e-02]\n",
      " [9.91536876e-01 8.46312423e-03]\n",
      " [1.66734560e-05 9.99983327e-01]\n",
      " [9.95292817e-01 4.70718317e-03]\n",
      " [9.84391321e-01 1.56086792e-02]\n",
      " [9.99865239e-01 1.34761222e-04]\n",
      " [9.99959049e-01 4.09509569e-05]\n",
      " [9.98685571e-01 1.31442886e-03]\n",
      " [1.31841739e-01 8.68158261e-01]\n",
      " [3.14263128e-06 9.99996857e-01]\n",
      " [1.69435837e-04 9.99830564e-01]\n",
      " [2.06769087e-04 9.99793231e-01]\n",
      " [9.99432947e-01 5.67052857e-04]\n",
      " [9.86204083e-01 1.37959172e-02]\n",
      " [9.93825316e-01 6.17468357e-03]\n",
      " [1.62807352e-03 9.98371926e-01]\n",
      " [9.94681092e-01 5.31890767e-03]\n",
      " [9.94799205e-01 5.20079489e-03]\n",
      " [9.99803254e-01 1.96745971e-04]\n",
      " [1.98627516e-05 9.99980137e-01]\n",
      " [9.73573138e-01 2.64268616e-02]\n",
      " [3.69967890e-08 9.99999963e-01]\n",
      " [3.78363386e-06 9.99996216e-01]\n",
      " [4.99488415e-04 9.99500512e-01]\n",
      " [9.99259311e-01 7.40688892e-04]\n",
      " [1.87940171e-04 9.99812060e-01]\n",
      " [2.17450113e-06 9.99997825e-01]\n",
      " [8.74699071e-01 1.25300929e-01]\n",
      " [9.93077485e-01 6.92251453e-03]\n",
      " [9.99922918e-01 7.70819200e-05]\n",
      " [2.06553936e-04 9.99793446e-01]\n",
      " [6.36720129e-03 9.93632799e-01]]\n",
      "['entertainment' 'tech']\n",
      "0               tech\n",
      "1      entertainment\n",
      "2      entertainment\n",
      "3      entertainment\n",
      "4      entertainment\n",
      "           ...      \n",
      "423    entertainment\n",
      "424    entertainment\n",
      "425             tech\n",
      "426    entertainment\n",
      "427             tech\n",
      "Name: Category, Length: 428, dtype: object\n",
      "probability 1 0.07068334481220445\n",
      "loss1 -2.6495453093311063\n",
      "probability 2 6.820133605678347e-05\n",
      "loss2 -9.593046403031327\n",
      "probability 2 1.6998544469792876e-06\n",
      "loss2 -13.284967929991604\n",
      "probability 2 0.9999001988429426\n",
      "loss2 -9.980613752428174e-05\n",
      "probability 2 0.9998609926135684\n",
      "loss2 -0.0001390170488537614\n",
      "probability 1 0.001429780167461627\n",
      "loss1 -6.550234575575655\n",
      "probability 2 0.9992248168783602\n",
      "loss2 -0.0007754837314376602\n",
      "probability 1 0.9997945875203198\n",
      "loss1 -0.00020543357971312742\n",
      "probability 1 0.007817942716944807\n",
      "loss1 -4.851333838711023\n",
      "probability 1 0.0010097765183767146\n",
      "loss1 -6.898026241546497\n",
      "probability 2 0.9992380862831209\n",
      "loss2 -0.0007622041206528252\n",
      "probability 2 0.0009189097589751283\n",
      "loss2 -6.992322635234008\n",
      "probability 1 0.010696836665538483\n",
      "loss1 -4.537807219958744\n",
      "probability 1 0.000838614591348852\n",
      "loss1 -7.083759323726167\n",
      "probability 1 5.740550339716078e-06\n",
      "loss1 -12.067955474229484\n",
      "probability 2 0.9981477392778743\n",
      "loss2 -0.0018539782782526386\n",
      "probability 2 0.9535605896795178\n",
      "loss2 -0.04755231146182167\n",
      "probability 1 0.00034592352115992006\n",
      "loss1 -7.96929284444891\n",
      "probability 1 0.987608531933585\n",
      "loss1 -0.012468882490526063\n",
      "probability 1 0.9999965577577988\n",
      "loss1 -3.442248125697459e-06\n",
      "probability 1 0.00016709037708457936\n",
      "loss1 -8.696975711785502\n",
      "probability 2 0.9997796920573421\n",
      "loss2 -0.0002203322140175736\n",
      "probability 1 0.9994025033024436\n",
      "loss1 -0.0005976752698426158\n",
      "probability 2 0.9887323238695\n",
      "loss2 -0.011331637309630823\n",
      "probability 1 0.9978953118427117\n",
      "loss1 -0.0021069061260427994\n",
      "probability 1 0.002109742780488218\n",
      "loss1 -6.1611892439070655\n",
      "probability 1 0.9937448095899135\n",
      "loss1 -0.006274836081410671\n",
      "probability 1 0.34245697695574756\n",
      "loss1 -1.071609243897792\n",
      "probability 2 0.9984939955205944\n",
      "loss2 -0.0015071396440034213\n",
      "probability 1 0.9997430835932078\n",
      "loss1 -0.0002569494154659586\n",
      "probability 2 0.9959966125654832\n",
      "loss2 -0.00401142244199383\n",
      "probability 1 0.9834420322452578\n",
      "loss1 -0.016696583159252907\n",
      "probability 1 0.9993926579169167\n",
      "loss1 -0.000607526589995928\n",
      "probability 1 0.9998970460536867\n",
      "loss1 -0.00010295924643463502\n",
      "probability 2 0.9777190232427222\n",
      "loss2 -0.02253294752292464\n",
      "probability 1 0.9937448095899135\n",
      "loss1 -0.006274836081410671\n",
      "probability 2 0.9891371361895239\n",
      "loss2 -0.010922295506391346\n",
      "probability 1 0.9996294764278248\n",
      "loss1 -0.000370592232994746\n",
      "probability 1 0.9954172221757467\n",
      "loss1 -0.004593310943496591\n",
      "probability 1 0.9903949387249427\n",
      "loss1 -0.009651487399129492\n",
      "probability 2 2.531840637587379e-06\n",
      "loss2 -12.886563995004586\n",
      "probability 2 0.9999592299630755\n",
      "loss2 -4.077086804503214e-05\n",
      "probability 1 5.33759438961709e-06\n",
      "loss1 -12.140735495328501\n",
      "probability 2 8.776693569689797e-07\n",
      "loss2 -13.945995900833529\n",
      "probability 2 0.9924505786141842\n",
      "loss2 -0.00757806250776573\n",
      "probability 2 0.9759287302909749\n",
      "loss2 -0.02436571747815189\n",
      "probability 1 0.5039767728567821\n",
      "loss1 -0.6852250975743652\n",
      "probability 2 0.9990909993770334\n",
      "loss2 -0.0009094140145673602\n",
      "probability 1 0.0006577206848389681\n",
      "loss1 -7.3267302078870085\n",
      "probability 2 0.014878191629665305\n",
      "loss2 -4.20785878722702\n",
      "probability 1 0.9268086134853688\n",
      "loss1 -0.07600819267624317\n",
      "probability 2 0.9788159789265373\n",
      "loss2 -0.021411622529976644\n",
      "probability 1 0.00010171514499762953\n",
      "loss1 -9.193334347632893\n",
      "probability 2 0.9983588838883917\n",
      "loss2 -0.001642464217788625\n",
      "probability 2 0.9904868753316445\n",
      "loss2 -0.009558663479887633\n",
      "probability 1 0.9999994498980203\n",
      "loss1 -5.501021310521812e-07\n",
      "probability 2 0.9926289711220062\n",
      "loss2 -0.007398329148136918\n",
      "probability 2 3.4435839280089198e-06\n",
      "loss2 -12.578997789379647\n",
      "probability 2 1.4182372171100965e-06\n",
      "loss2 -13.466095853923242\n",
      "probability 1 0.999945327156808\n",
      "loss1 -5.467433780641771e-05\n",
      "probability 2 0.00010435498520278141\n",
      "loss2 -9.167712151717499\n",
      "probability 2 5.530984694246399e-06\n",
      "loss2 -12.10514469422253\n",
      "probability 2 0.8374870497625594\n",
      "loss2 -0.17734947837254686\n",
      "probability 1 0.9994845163309313\n",
      "loss1 -0.0005156165764516192\n",
      "probability 1 0.20017522620402678\n",
      "loss1 -1.6085621649927215\n",
      "probability 2 0.9929480710756455\n",
      "loss2 -0.007076911293674508\n",
      "probability 1 0.9999998107841646\n",
      "loss1 -1.8921585334571913e-07\n",
      "probability 1 0.009008597077978608\n",
      "loss1 -4.709575926702098\n",
      "probability 2 0.9984713285005294\n",
      "loss2 -0.00152984110986589\n",
      "probability 2 1.6998544469792876e-06\n",
      "loss2 -13.284967929991604\n",
      "probability 2 0.9992581168392544\n",
      "loss2 -0.0007421584922420261\n",
      "probability 2 0.9999998424569062\n",
      "loss2 -1.5754310620270357e-07\n",
      "probability 2 0.003465768537949665\n",
      "loss2 -5.664820870660241\n",
      "probability 2 0.9953488407964991\n",
      "loss2 -0.0046620095018519445\n",
      "probability 1 0.011902828838301687\n",
      "loss1 -4.430979189610639\n",
      "probability 2 0.9915368757691928\n",
      "loss2 -0.008499139813542219\n",
      "probability 2 1.6673455980775742e-05\n",
      "loss2 -11.001692565305783\n",
      "probability 1 0.0047071831720802435\n",
      "loss1 -5.358665602495513\n",
      "probability 2 0.9843913207688304\n",
      "loss2 -0.0157317772769299\n",
      "probability 2 0.9998652387780889\n",
      "loss2 -0.0001347703030204683\n",
      "probability 1 4.095095689020741e-05\n",
      "loss1 -10.103135380655974\n",
      "probability 1 0.001314428859089593\n",
      "loss1 -6.634353035388521\n",
      "probability 1 0.8681582609864785\n",
      "loss1 -0.1413812526161398\n",
      "probability 1 0.9999968573687205\n",
      "loss1 -3.142636217616201e-06\n",
      "probability 2 0.00016943583718342925\n",
      "loss2 -8.683036244499444\n",
      "probability 2 0.0002067690871268013\n",
      "loss2 -8.483907908482262\n",
      "probability 2 0.9994329471433535\n",
      "loss2 -0.0005672136919218794\n",
      "probability 1 0.013795917157414184\n",
      "loss1 -4.28338258875203\n",
      "probability 2 0.9938253164345495\n",
      "loss2 -0.006193825762704518\n",
      "probability 2 0.0016280735198045404\n",
      "loss2 -6.420357852836354\n",
      "probability 1 0.005318907672604246\n",
      "loss1 -5.236487321409036\n",
      "probability 1 0.005200794886295338\n",
      "loss1 -5.2589438023279715\n",
      "probability 1 0.00019674597061148516\n",
      "loss1 -8.533597150614796\n",
      "probability 1 0.9999801372483627\n",
      "loss1 -1.9862948904408564e-05\n",
      "probability 2 0.9735731384371291\n",
      "loss2 -0.02678232762664227\n",
      "probability 2 3.699678896573744e-08\n",
      "loss2 -17.112434712777997\n",
      "probability 1 0.9999962163661357\n",
      "loss1 -3.7836410222900038e-06\n",
      "probability 1 0.9995005115849979\n",
      "loss1 -0.0004996132008949655\n",
      "probability 1 0.0007406888921686616\n",
      "loss1 -7.207929869454587\n",
      "probability 1 0.9998120598291574\n",
      "loss1 -0.00018795783380955674\n",
      "probability 1 0.99999782549887\n",
      "loss1 -2.174503494278811e-06\n",
      "probability 2 0.874699071374049\n",
      "loss2 -0.13387537020768708\n",
      "probability 2 0.9930774854698936\n",
      "loss2 -0.006946586289542794\n",
      "probability 1 7.708192003937504e-05\n",
      "loss1 -9.470641805032255\n",
      "probability 2 0.0002065539363941271\n",
      "loss2 -8.48494898647629\n",
      "probability 1 0.9936327987146355\n",
      "loss1 -0.0063875583692421965\n",
      "0.047091090090211896\n",
      "[[9.10832768e-01 8.91672322e-02]\n",
      " [2.06581346e-04 9.99793419e-01]\n",
      " [1.66579676e-05 9.99983342e-01]\n",
      " [9.99982150e-01 1.78497813e-05]\n",
      " [9.99982091e-01 1.79093026e-05]\n",
      " [9.99350203e-01 6.49797094e-04]\n",
      " [9.99619737e-01 3.80263236e-04]\n",
      " [2.15372768e-04 9.99784627e-01]\n",
      " [9.93198367e-01 6.80163309e-03]\n",
      " [9.99321158e-01 6.78841847e-04]\n",
      " [9.99752960e-01 2.47040106e-04]\n",
      " [1.49276944e-03 9.98507231e-01]\n",
      " [9.85096430e-01 1.49035703e-02]\n",
      " [9.99321324e-01 6.78675899e-04]\n",
      " [9.99998566e-01 1.43357601e-06]\n",
      " [9.99517170e-01 4.82829698e-04]\n",
      " [9.31969211e-01 6.80307887e-02]\n",
      " [9.99809989e-01 1.90010559e-04]\n",
      " [2.78503065e-03 9.97214969e-01]\n",
      " [2.10542431e-06 9.99997895e-01]\n",
      " [9.99954220e-01 4.57797711e-05]\n",
      " [9.99954861e-01 4.51393859e-05]\n",
      " [7.00115426e-04 9.99299885e-01]\n",
      " [9.67220207e-01 3.27797929e-02]\n",
      " [3.26896265e-03 9.96731037e-01]\n",
      " [9.98088873e-01 1.91112668e-03]\n",
      " [1.09694528e-02 9.89030547e-01]\n",
      " [7.60929119e-01 2.39070881e-01]\n",
      " [9.99251787e-01 7.48213447e-04]\n",
      " [4.24838601e-04 9.99575161e-01]\n",
      " [9.94296124e-01 5.70387641e-03]\n",
      " [2.71162642e-02 9.72883736e-01]\n",
      " [1.73991964e-03 9.98260080e-01]\n",
      " [5.04759065e-04 9.99495241e-01]\n",
      " [9.92079263e-01 7.92073674e-03]\n",
      " [1.09694528e-02 9.89030547e-01]\n",
      " [9.95001029e-01 4.99897115e-03]\n",
      " [1.70812767e-04 9.99829187e-01]\n",
      " [3.56661331e-03 9.96433387e-01]\n",
      " [5.80168732e-03 9.94198313e-01]\n",
      " [1.42524125e-05 9.99985748e-01]\n",
      " [9.99993639e-01 6.36093359e-06]\n",
      " [9.99998308e-01 1.69162492e-06]\n",
      " [7.63017305e-06 9.99992370e-01]\n",
      " [9.95751732e-01 4.24826783e-03]\n",
      " [9.83146810e-01 1.68531897e-02]\n",
      " [5.48499899e-01 4.51500101e-01]\n",
      " [9.98877804e-01 1.12219645e-03]\n",
      " [9.99586778e-01 4.13221540e-04]\n",
      " [1.58963327e-02 9.84103667e-01]\n",
      " [3.73317530e-02 9.62668247e-01]\n",
      " [9.81290079e-01 1.87099205e-02]\n",
      " [9.99986488e-01 1.35122423e-05]\n",
      " [9.96935206e-01 3.06479449e-03]\n",
      " [9.93937755e-01 6.06224462e-03]\n",
      " [3.90291331e-06 9.99996097e-01]\n",
      " [9.96796432e-01 3.20356814e-03]\n",
      " [1.96822491e-05 9.99980318e-01]\n",
      " [2.64203642e-06 9.99997358e-01]\n",
      " [1.83289454e-04 9.99816711e-01]\n",
      " [1.37067833e-04 9.99862932e-01]\n",
      " [1.37607050e-05 9.99986239e-01]\n",
      " [9.34607693e-01 6.53923072e-02]\n",
      " [1.26281791e-03 9.98737182e-01]\n",
      " [9.43613908e-01 5.63860923e-02]\n",
      " [9.95019403e-01 4.98059731e-03]\n",
      " [2.07716851e-07 9.99999792e-01]\n",
      " [9.93070385e-01 6.92961539e-03]\n",
      " [9.99572103e-01 4.27897079e-04]\n",
      " [1.66579676e-05 9.99983342e-01]\n",
      " [9.99451249e-01 5.48751135e-04]\n",
      " [9.99999999e-01 1.32857214e-09]\n",
      " [2.94176972e-03 9.97058230e-01]\n",
      " [9.97388727e-01 2.61127268e-03]\n",
      " [9.85655569e-01 1.43444314e-02]\n",
      " [9.92703755e-01 7.29624488e-03]\n",
      " [2.32599800e-05 9.99976740e-01]\n",
      " [9.98604144e-01 1.39585584e-03]\n",
      " [9.99108734e-01 8.91265907e-04]\n",
      " [9.99972352e-01 2.76484703e-05]\n",
      " [9.99990729e-01 9.27117335e-06]\n",
      " [9.99882850e-01 1.17149693e-04]\n",
      " [6.66637242e-02 9.33336276e-01]\n",
      " [1.76766280e-05 9.99982323e-01]\n",
      " [1.46166220e-04 9.99853834e-01]\n",
      " [4.44560782e-04 9.99555439e-01]\n",
      " [9.99785840e-01 2.14159623e-04]\n",
      " [9.93744191e-01 6.25580889e-03]\n",
      " [9.95558448e-01 4.44155247e-03]\n",
      " [3.09589379e-03 9.96904106e-01]\n",
      " [9.95559010e-01 4.44099022e-03]\n",
      " [9.99119235e-01 8.80765226e-04]\n",
      " [9.99946049e-01 5.39508153e-05]\n",
      " [4.32868689e-05 9.99956713e-01]\n",
      " [9.64415436e-01 3.55845639e-02]\n",
      " [2.86865549e-07 9.99999713e-01]\n",
      " [1.46828388e-05 9.99985317e-01]\n",
      " [8.12777477e-04 9.99187223e-01]\n",
      " [9.99603015e-01 3.96984688e-04]\n",
      " [6.78009201e-04 9.99321991e-01]\n",
      " [6.37687620e-06 9.99993623e-01]\n",
      " [7.51967940e-01 2.48032060e-01]\n",
      " [9.92561339e-01 7.43866140e-03]\n",
      " [9.99990851e-01 9.14922872e-06]\n",
      " [3.31537714e-04 9.99668462e-01]\n",
      " [4.39504967e-03 9.95604950e-01]]\n",
      "['entertainment' 'tech']\n",
      "0               tech\n",
      "1      entertainment\n",
      "2      entertainment\n",
      "3      entertainment\n",
      "4      entertainment\n",
      "           ...      \n",
      "423    entertainment\n",
      "424    entertainment\n",
      "425             tech\n",
      "426    entertainment\n",
      "427             tech\n",
      "Name: Category, Length: 428, dtype: object\n",
      "probability 1 0.08916723215899222\n",
      "loss1 -2.4172416593642896\n",
      "probability 2 0.00020658134584639054\n",
      "loss2 -8.484816296515003\n",
      "probability 2 1.6657967593314282e-05\n",
      "loss2 -11.002621921865776\n",
      "probability 2 0.9999821502187135\n",
      "loss2 -1.7849940595735917e-05\n",
      "probability 2 0.9999820906974046\n",
      "loss2 -1.7909462968850334e-05\n",
      "probability 1 0.0006497970939123729\n",
      "loss1 -7.338850407019403\n",
      "probability 2 0.9996197367643785\n",
      "loss2 -0.00038033555401957434\n",
      "probability 1 0.9997846272323362\n",
      "loss1 -0.00021539596370892918\n",
      "probability 1 0.0068016330920922935\n",
      "loss1 -4.990592535032209\n",
      "probability 1 0.0006788418472776618\n",
      "loss1 -7.295122377598022\n",
      "probability 2 0.9997529598940513\n",
      "loss2 -0.00024707062538209686\n",
      "probability 2 0.001492769444590647\n",
      "loss2 -6.507122196602484\n",
      "probability 1 0.01490357025021839\n",
      "loss1 -4.206154480624982\n",
      "probability 1 0.0006786758994768596\n",
      "loss1 -7.295366864717289\n",
      "probability 1 1.4335760147894258e-06\n",
      "loss1 -13.45533852562085\n",
      "probability 2 0.9995171703017749\n",
      "loss2 -0.0004829462980172564\n",
      "probability 2 0.9319692112692539\n",
      "loss2 -0.0704554999610437\n",
      "probability 1 0.00019001055939752486\n",
      "loss1 -8.568430911571618\n",
      "probability 1 0.9972149693528426\n",
      "loss1 -0.002788916060684132\n",
      "probability 1 0.9999978945756932\n",
      "loss1 -2.105426523195263e-06\n",
      "probability 1 4.577977111511355e-05\n",
      "loss1 -9.991668243122218\n",
      "probability 2 0.999954860614139\n",
      "loss2 -4.5140404673774286e-05\n",
      "probability 1 0.9992998845735589\n",
      "loss1 -0.0007003606216962761\n",
      "probability 2 0.9672202071308489\n",
      "loss2 -0.03332908749817523\n",
      "probability 1 0.9967310373481881\n",
      "loss1 -0.0032743173830167326\n",
      "probability 1 0.0019111266833322948\n",
      "loss1 -6.260062324276875\n",
      "probability 1 0.9890305471510255\n",
      "loss1 -0.011030060929413148\n",
      "probability 1 0.2390708814786994\n",
      "loss1 -1.4309951957956812\n",
      "probability 2 0.9992517865528094\n",
      "loss2 -0.0007484934985726917\n",
      "probability 1 0.999575161399027\n",
      "loss1 -0.0004249288704589617\n",
      "probability 2 0.9942961235875797\n",
      "loss2 -0.005720205638346601\n",
      "probability 1 0.972883735803132\n",
      "loss1 -0.02749069437439643\n",
      "probability 1 0.9982600803552666\n",
      "loss1 -0.0017414350629775652\n",
      "probability 1 0.999495240934582\n",
      "loss1 -0.0005048864991591147\n",
      "probability 2 0.9920792632576085\n",
      "loss2 -0.007952272411869217\n",
      "probability 1 0.9890305471510255\n",
      "loss1 -0.011030060929413148\n",
      "probability 2 0.9950010288507035\n",
      "loss2 -0.005011507803271326\n",
      "probability 1 0.9998291872326537\n",
      "loss1 -0.000170827357508543\n",
      "probability 1 0.9964333866902815\n",
      "loss1 -0.003572988838847978\n",
      "probability 1 0.9941983126756132\n",
      "loss1 -0.005818582490965983\n",
      "probability 2 1.4252412471549292e-05\n",
      "loss2 -11.158584369329533\n",
      "probability 2 0.999993639066405\n",
      "loss2 -6.360953825786039e-06\n",
      "probability 1 1.6916249207715926e-06\n",
      "loss1 -13.289820999385423\n",
      "probability 2 7.630173050388045e-06\n",
      "loss2 -11.783400032664545\n",
      "probability 2 0.9957517321699096\n",
      "loss2 -0.004257317358843867\n",
      "probability 2 0.9831468102975504\n",
      "loss2 -0.01699682075191964\n",
      "probability 1 0.4515001007040238\n",
      "loss1 -0.7951796830818797\n",
      "probability 2 0.9988778035506468\n",
      "loss2 -0.0011228265832554532\n",
      "probability 1 0.00041322153956458926\n",
      "loss1 -7.791526693411931\n",
      "probability 2 0.015896332748444486\n",
      "loss2 -4.141666841110462\n",
      "probability 1 0.9626682469915651\n",
      "loss1 -0.038046426027140784\n",
      "probability 2 0.981290079490059\n",
      "loss2 -0.018887165379479567\n",
      "probability 1 1.3512242300365915e-05\n",
      "loss1 -11.211914446384068\n",
      "probability 2 0.9969352055065238\n",
      "loss2 -0.0030695005940670713\n",
      "probability 2 0.9939377553840741\n",
      "loss2 -0.006080694624251815\n",
      "probability 1 0.9999960970866891\n",
      "loss1 -3.902920927257421e-06\n",
      "probability 2 0.9967964318616899\n",
      "loss2 -0.003208710548362869\n",
      "probability 2 1.968224905035676e-05\n",
      "loss2 -10.835793391855681\n",
      "probability 2 2.6420364227508486e-06\n",
      "loss2 -12.843960565906613\n",
      "probability 1 0.9998167105457206\n",
      "loss1 -0.00018330625384421236\n",
      "probability 2 0.00013706783298350622\n",
      "loss2 -8.895034623406719\n",
      "probability 2 1.3760705043885935e-05\n",
      "loss2 -11.19369348811723\n",
      "probability 2 0.934607692797624\n",
      "loss2 -0.06762841763731345\n",
      "probability 1 0.9987371820884244\n",
      "loss1 -0.0012636159380266087\n",
      "probability 1 0.05638609231587945\n",
      "loss1 -2.8755327410304536\n",
      "probability 2 0.9950194026927308\n",
      "loss2 -0.004993041819971277\n",
      "probability 1 0.9999997922831488\n",
      "loss1 -2.0771687273697866e-07\n",
      "probability 1 0.006929615387622851\n",
      "loss1 -4.971950966942008\n",
      "probability 2 0.9995721029208854\n",
      "loss2 -0.0004279886531935572\n",
      "probability 2 1.6657967593314282e-05\n",
      "loss2 -11.002621921865776\n",
      "probability 2 0.9994512488651012\n",
      "loss2 -0.0005489017539069429\n",
      "probability 2 0.9999999986714279\n",
      "loss2 -1.3285721420729724e-09\n",
      "probability 2 0.002941769718648235\n",
      "loss2 -5.828743933609393\n",
      "probability 2 0.9973887273175717\n",
      "loss2 -0.0026146880017883564\n",
      "probability 1 0.014344431417629932\n",
      "loss1 -4.244393466609709\n",
      "probability 2 0.9927037551190595\n",
      "loss2 -0.0073229926606049175\n",
      "probability 2 2.325997999030882e-05\n",
      "loss2 -10.668776271136\n",
      "probability 1 0.0013958558425787185\n",
      "loss1 -6.574247544602541\n",
      "probability 2 0.9991087340929014\n",
      "loss2 -0.0008916633207089077\n",
      "probability 2 0.9999723515297282\n",
      "loss2 -2.764885249781223e-05\n",
      "probability 1 9.27117335151166e-06\n",
      "loss1 -11.588600611260366\n",
      "probability 1 0.00011714969324454066\n",
      "loss1 -9.0520580114984\n",
      "probability 1 0.933336275826644\n",
      "loss1 -0.0689897188205168\n",
      "probability 1 0.9999823233720284\n",
      "loss1 -1.767678420501499e-05\n",
      "probability 2 0.00014616621951679676\n",
      "loss2 -8.830766094002955\n",
      "probability 2 0.00044456078247634423\n",
      "loss2 -7.718423768880013\n",
      "probability 2 0.999785840377072\n",
      "loss2 -0.00021418255837470324\n",
      "probability 1 0.006255808889174773\n",
      "loss1 -5.0742448246113065\n",
      "probability 2 0.9955584475293707\n",
      "loss2 -0.004451445469186888\n",
      "probability 2 0.003095893787288806\n",
      "loss2 -5.7776786302744\n",
      "probability 1 0.004440990222093833\n",
      "loss1 -5.416877904409828\n",
      "probability 1 0.0008807652255059175\n",
      "loss1 -7.034719453914295\n",
      "probability 1 5.395081526725124e-05\n",
      "loss1 -9.827437754840458\n",
      "probability 1 0.9999567131310662\n",
      "loss1 -4.328780583739326e-05\n",
      "probability 2 0.964415436055518\n",
      "loss2 -0.03623312693892689\n",
      "probability 2 2.8686554875978487e-07\n",
      "loss2 -15.064252202173977\n",
      "probability 1 0.9999853171611677\n",
      "loss1 -1.4682946626258255e-05\n",
      "probability 1 0.999187222522782\n",
      "loss1 -0.0008131079599164406\n",
      "probability 1 0.0003969846881854518\n",
      "loss1 -7.831612846823267\n",
      "probability 1 0.9993219907994414\n",
      "loss1 -0.000678239152742298\n",
      "probability 1 0.9999936231238016\n",
      "loss1 -6.376896530783218e-06\n",
      "probability 2 0.7519679402732665\n",
      "loss2 -0.2850615885564301\n",
      "probability 2 0.9925613386009866\n",
      "loss2 -0.007466466213600635\n",
      "probability 1 9.149228717174352e-06\n",
      "loss1 -11.601840975434705\n",
      "probability 2 0.00033153771374117014\n",
      "loss2 -8.011768987867635\n",
      "probability 1 0.9956049503270243\n",
      "loss1 -0.004404736296336351\n",
      "0.04600476284224227\n",
      "[[9.39401711e-01 6.05982886e-02]\n",
      " [2.91460797e-04 9.99708539e-01]\n",
      " [5.50885048e-06 9.99994491e-01]\n",
      " [9.99989107e-01 1.08933608e-05]\n",
      " [9.99986669e-01 1.33312241e-05]\n",
      " [9.99306981e-01 6.93019241e-04]\n",
      " [9.99888592e-01 1.11408181e-04]\n",
      " [2.80876015e-04 9.99719124e-01]\n",
      " [9.95613024e-01 4.38697603e-03]\n",
      " [9.99070426e-01 9.29574218e-04]\n",
      " [9.99790286e-01 2.09714492e-04]\n",
      " [7.28593986e-04 9.99271406e-01]\n",
      " [9.89886511e-01 1.01134892e-02]\n",
      " [9.99341618e-01 6.58382164e-04]\n",
      " [9.99999616e-01 3.84450803e-07]\n",
      " [9.99643557e-01 3.56443313e-04]\n",
      " [9.58620240e-01 4.13797602e-02]\n",
      " [9.99883844e-01 1.16155822e-04]\n",
      " [1.25639551e-02 9.87436045e-01]\n",
      " [3.48128688e-06 9.99996519e-01]\n",
      " [9.99945916e-01 5.40836953e-05]\n",
      " [9.99941444e-01 5.85555525e-05]\n",
      " [5.61878021e-04 9.99438122e-01]\n",
      " [9.75663881e-01 2.43361190e-02]\n",
      " [3.16364911e-03 9.96836351e-01]\n",
      " [9.96989990e-01 3.01001001e-03]\n",
      " [1.46172288e-02 9.85382771e-01]\n",
      " [7.91821976e-01 2.08178024e-01]\n",
      " [9.99399254e-01 6.00746152e-04]\n",
      " [3.02061303e-04 9.99697939e-01]\n",
      " [9.95858455e-01 4.14154521e-03]\n",
      " [2.25013044e-02 9.77498696e-01]\n",
      " [1.58955173e-03 9.98410448e-01]\n",
      " [3.26080605e-04 9.99673919e-01]\n",
      " [9.89103304e-01 1.08966955e-02]\n",
      " [1.46172288e-02 9.85382771e-01]\n",
      " [9.96318762e-01 3.68123813e-03]\n",
      " [4.01396906e-04 9.99598603e-01]\n",
      " [4.53079377e-03 9.95469206e-01]\n",
      " [1.58443770e-02 9.84155623e-01]\n",
      " [7.56012520e-06 9.99992440e-01]\n",
      " [9.99990442e-01 9.55801834e-06]\n",
      " [9.99999288e-01 7.11840148e-07]\n",
      " [6.06270519e-07 9.99999394e-01]\n",
      " [9.94739531e-01 5.26046867e-03]\n",
      " [9.59674716e-01 4.03252837e-02]\n",
      " [5.57912290e-01 4.42087710e-01]\n",
      " [9.99418138e-01 5.81862039e-04]\n",
      " [9.99743882e-01 2.56118202e-04]\n",
      " [1.67558377e-02 9.83244162e-01]\n",
      " [8.03072052e-02 9.19692795e-01]\n",
      " [9.77607727e-01 2.23922727e-02]\n",
      " [9.99982113e-01 1.78874599e-05]\n",
      " [9.97388412e-01 2.61158819e-03]\n",
      " [9.94564568e-01 5.43543165e-03]\n",
      " [4.79046877e-06 9.99995210e-01]\n",
      " [9.96516050e-01 3.48394961e-03]\n",
      " [1.22240326e-05 9.99987776e-01]\n",
      " [1.04806062e-05 9.99989519e-01]\n",
      " [1.87809852e-04 9.99812190e-01]\n",
      " [1.12466052e-04 9.99887534e-01]\n",
      " [2.36186845e-05 9.99976381e-01]\n",
      " [9.25226473e-01 7.47735272e-02]\n",
      " [6.02342552e-04 9.99397657e-01]\n",
      " [8.56363621e-01 1.43636379e-01]\n",
      " [9.95830842e-01 4.16915816e-03]\n",
      " [5.02831293e-07 9.99999497e-01]\n",
      " [9.86748321e-01 1.32516791e-02]\n",
      " [9.99569418e-01 4.30582498e-04]\n",
      " [5.50885048e-06 9.99994491e-01]\n",
      " [9.99533982e-01 4.66018019e-04]\n",
      " [9.99999999e-01 7.96602802e-10]\n",
      " [1.60242310e-03 9.98397577e-01]\n",
      " [9.96995142e-01 3.00485751e-03]\n",
      " [9.89770005e-01 1.02299954e-02]\n",
      " [9.96600783e-01 3.39921708e-03]\n",
      " [2.71301019e-05 9.99972870e-01]\n",
      " [9.96461483e-01 3.53851732e-03]\n",
      " [9.96814714e-01 3.18528623e-03]\n",
      " [9.99985292e-01 1.47078807e-05]\n",
      " [9.99994867e-01 5.13285476e-06]\n",
      " [9.99814631e-01 1.85369169e-04]\n",
      " [8.99988349e-02 9.10001165e-01]\n",
      " [1.60323838e-05 9.99983968e-01]\n",
      " [1.07202843e-04 9.99892797e-01]\n",
      " [5.32819994e-04 9.99467180e-01]\n",
      " [9.99720342e-01 2.79658384e-04]\n",
      " [9.88075185e-01 1.19248147e-02]\n",
      " [9.92795371e-01 7.20462948e-03]\n",
      " [4.00838140e-03 9.95991619e-01]\n",
      " [9.96516140e-01 3.48386029e-03]\n",
      " [9.98926758e-01 1.07324239e-03]\n",
      " [9.99978280e-01 2.17196739e-05]\n",
      " [5.38833554e-05 9.99946117e-01]\n",
      " [9.87108912e-01 1.28910881e-02]\n",
      " [2.37606702e-07 9.99999762e-01]\n",
      " [2.00867999e-05 9.99979913e-01]\n",
      " [5.20102753e-04 9.99479897e-01]\n",
      " [9.99765003e-01 2.34996562e-04]\n",
      " [8.24800309e-04 9.99175200e-01]\n",
      " [2.55421238e-06 9.99997446e-01]\n",
      " [7.86350032e-01 2.13649968e-01]\n",
      " [9.92740665e-01 7.25933519e-03]\n",
      " [9.99971457e-01 2.85434058e-05]\n",
      " [4.10248270e-04 9.99589752e-01]\n",
      " [5.22286471e-03 9.94777135e-01]]\n",
      "['entertainment' 'tech']\n",
      "0               tech\n",
      "1      entertainment\n",
      "2      entertainment\n",
      "3      entertainment\n",
      "4      entertainment\n",
      "           ...      \n",
      "423    entertainment\n",
      "424    entertainment\n",
      "425             tech\n",
      "426    entertainment\n",
      "427             tech\n",
      "Name: Category, Length: 428, dtype: object\n",
      "probability 1 0.060598288599412915\n",
      "loss1 -2.8034886272394313\n",
      "probability 2 0.0002914607974900951\n",
      "loss2 -8.140605046671926\n",
      "probability 2 5.508850481450445e-06\n",
      "loss2 -12.109154580620658\n",
      "probability 2 0.9999891066392466\n",
      "loss2 -1.0893420086524085e-05\n",
      "probability 2 0.9999866687758893\n",
      "loss2 -1.3331312972293186e-05\n",
      "probability 1 0.0006930192409238364\n",
      "loss1 -7.274452794478941\n",
      "probability 2 0.9998885918193261\n",
      "loss2 -0.00011141438702622356\n",
      "probability 1 0.9997191239851686\n",
      "loss1 -0.00028091546788703745\n",
      "probability 1 0.0043869760275358554\n",
      "loss1 -5.429115121245209\n",
      "probability 1 0.0009295742176365715\n",
      "loss1 -6.980783907151665\n",
      "probability 2 0.9997902855079565\n",
      "loss2 -0.00020973648520254093\n",
      "probability 2 0.0007285939858026058\n",
      "loss2 -7.224393927880912\n",
      "probability 1 0.010113489227579268\n",
      "loss1 -4.593885179124283\n",
      "probability 1 0.0006583821639633173\n",
      "loss1 -7.325724998939014\n",
      "probability 1 3.844508031963883e-07\n",
      "loss1 -14.771450006261434\n",
      "probability 2 0.9996435566868505\n",
      "loss2 -0.0003565068541669195\n",
      "probability 2 0.9586202398043719\n",
      "loss2 -0.04226027855881338\n",
      "probability 1 0.00011615582245082525\n",
      "loss1 -9.060577971284282\n",
      "probability 1 0.9874360448664915\n",
      "loss1 -0.012643548996343852\n",
      "probability 1 0.9999965187131175\n",
      "loss1 -3.4812929422383636e-06\n",
      "probability 1 5.408369527592084e-05\n",
      "loss1 -9.824977798757711\n",
      "probability 2 0.9999414444474811\n",
      "loss2 -5.855726696217218e-05\n",
      "probability 1 0.9994381219793018\n",
      "loss1 -0.0005620359333077731\n",
      "probability 2 0.9756638809856818\n",
      "loss2 -0.02463713611889556\n",
      "probability 1 0.9968363508855514\n",
      "loss1 -0.003168664032061201\n",
      "probability 1 0.003010010007647914\n",
      "loss1 -5.805811875426908\n",
      "probability 1 0.9853827711853119\n",
      "loss1 -0.014725113107412195\n",
      "probability 1 0.20817802356321907\n",
      "loss1 -1.569361682823929\n",
      "probability 2 0.9993992538479346\n",
      "loss2 -0.0006009266723365379\n",
      "probability 1 0.9996979386971401\n",
      "loss1 -0.00030210693256414327\n",
      "probability 2 0.9958584547886433\n",
      "loss2 -0.00415014516266344\n",
      "probability 1 0.9774986955863366\n",
      "loss1 -0.022758321562036894\n",
      "probability 1 0.9984104482669535\n",
      "loss1 -0.0015908164107606597\n",
      "probability 1 0.9996739193948044\n",
      "loss1 -0.0003261337810361634\n",
      "probability 2 0.9891033044719622\n",
      "loss2 -0.010956499354285344\n",
      "probability 1 0.9853827711853119\n",
      "loss1 -0.014725113107412195\n",
      "probability 2 0.9963187618694068\n",
      "loss2 -0.0036880305625103206\n",
      "probability 1 0.9995986030936156\n",
      "loss1 -0.0004014774876867495\n",
      "probability 1 0.9954692062295255\n",
      "loss1 -0.0045410889251544665\n",
      "probability 1 0.9841556230039477\n",
      "loss1 -0.015971240975527125\n",
      "probability 2 7.5601251957602145e-06\n",
      "loss2 -11.792622807624209\n",
      "probability 2 0.9999904419816645\n",
      "loss2 -9.558064013613192e-06\n",
      "probability 1 7.118401484285912e-07\n",
      "loss1 -14.155412461374722\n",
      "probability 2 6.062705194542772e-07\n",
      "loss2 -14.31593954874498\n",
      "probability 2 0.9947395313311388\n",
      "loss2 -0.00527435364991412\n",
      "probability 2 0.9596747162864867\n",
      "loss2 -0.041160889140126736\n",
      "probability 1 0.4420877104870028\n",
      "loss1 -0.8162469765752111\n",
      "probability 2 0.9994181379612194\n",
      "loss2 -0.0005820313861911268\n",
      "probability 1 0.00025611820157777227\n",
      "loss1 -8.269871495133685\n",
      "probability 2 0.0167558376788165\n",
      "loss2 -4.089008563291102\n",
      "probability 1 0.9196927948077444\n",
      "loss1 -0.08371558338954424\n",
      "probability 2 0.9776077272845242\n",
      "loss2 -0.022646786254265285\n",
      "probability 1 1.7887459854507012e-05\n",
      "loss1 -10.931410657416466\n",
      "probability 2 0.9973884118109365\n",
      "loss2 -0.00261500433450439\n",
      "probability 2 0.9945645683533229\n",
      "loss2 -0.005450257352414743\n",
      "probability 1 0.9999952095312294\n",
      "loss1 -4.790480244886833e-06\n",
      "probability 2 0.9965160503926763\n",
      "loss2 -0.003490032692641634\n",
      "probability 2 1.222403258738236e-05\n",
      "loss2 -11.312106659691048\n",
      "probability 2 1.0480606171703322e-05\n",
      "loss2 -11.465984039932708\n",
      "probability 1 0.9998121901479631\n",
      "loss1 -0.00018782749051567328\n",
      "probability 2 0.00011246605164361156\n",
      "loss2 -9.092859145027363\n",
      "probability 2 2.3618684545367863e-05\n",
      "loss2 -10.65347244115204\n",
      "probability 2 0.9252264727899489\n",
      "loss2 -0.07771673598842568\n",
      "probability 1 0.9993976574477429\n",
      "loss1 -0.0006025240334117771\n",
      "probability 1 0.14363637888562397\n",
      "loss1 -1.9404703195937643\n",
      "probability 2 0.9958308418365008\n",
      "loss2 -0.004177873335115885\n",
      "probability 1 0.9999994971687073\n",
      "loss1 -5.02831419134364e-07\n",
      "probability 1 0.013251679125778772\n",
      "loss1 -4.323631008105157\n",
      "probability 2 0.9995694175021141\n",
      "loss2 -0.00043067522514837867\n",
      "probability 2 5.508850481450445e-06\n",
      "loss2 -12.109154580620658\n",
      "probability 2 0.9995339819814607\n",
      "loss2 -0.0004661266386833691\n",
      "probability 2 0.9999999992033972\n",
      "loss2 -7.966027840542318e-10\n",
      "probability 2 0.0016024231017200963\n",
      "loss2 -6.436238356766953\n",
      "probability 2 0.9969951424929652\n",
      "loss2 -0.0030093811555725993\n",
      "probability 1 0.010229995437728026\n",
      "loss1 -4.5824311449885915\n",
      "probability 2 0.9966007829164033\n",
      "loss2 -0.0034050075477409696\n",
      "probability 2 2.7130101914241145e-05\n",
      "loss2 -10.514866674785887\n",
      "probability 1 0.003538517321450712\n",
      "loss1 -5.644047475321031\n",
      "probability 2 0.9968147137739213\n",
      "loss2 -0.003190370048740417\n",
      "probability 2 0.9999852921193038\n",
      "loss2 -1.4707988858178694e-05\n",
      "probability 1 5.132854763069304e-06\n",
      "loss1 -12.17984856953231\n",
      "probability 1 0.00018536916900836238\n",
      "loss1 -8.593161213114252\n",
      "probability 1 0.9100011650511508\n",
      "loss1 -0.09430939919607098\n",
      "probability 1 0.9999839676161646\n",
      "loss1 -1.603251235544644e-05\n",
      "probability 2 0.00010720284264975621\n",
      "loss2 -9.14078779242396\n",
      "probability 2 0.0005328199936178724\n",
      "loss2 -7.537326913883091\n",
      "probability 2 0.9997203416158835\n",
      "loss2 -0.00027969749581449295\n",
      "probability 1 0.011924814668360132\n",
      "loss1 -4.429133783765807\n",
      "probability 2 0.9927953705242081\n",
      "loss2 -0.007230708152361773\n",
      "probability 2 0.004008381404355776\n",
      "loss2 -5.519367758959663\n",
      "probability 1 0.0034838602881461546\n",
      "loss1 -5.659614321787291\n",
      "probability 1 0.0010732423949640383\n",
      "loss1 -6.837070936872095\n",
      "probability 1 2.1719673885858052e-05\n",
      "loss1 -10.737292077474516\n",
      "probability 1 0.9999461166446169\n",
      "loss1 -5.388480714328853e-05\n",
      "probability 2 0.9871089119414118\n",
      "loss2 -0.012974899191177211\n",
      "probability 2 2.3760670198047507e-07\n",
      "loss2 -15.2526490428672\n",
      "probability 1 0.9999799132000986\n",
      "loss1 -2.0087001643864328e-05\n",
      "probability 1 0.9994798972468316\n",
      "loss1 -0.0005202380535207343\n",
      "probability 1 0.00023499656245380208\n",
      "loss1 -8.355939671783265\n",
      "probability 1 0.9991751996909172\n",
      "loss1 -0.0008251406440095311\n",
      "probability 1 0.9999974457876225\n",
      "loss1 -2.5542156394984155e-06\n",
      "probability 2 0.7863500323824988\n",
      "loss2 -0.24035325186463308\n",
      "probability 2 0.9927406648106646\n",
      "loss2 -0.00728581237871051\n",
      "probability 1 2.854340579148491e-05\n",
      "loss1 -10.464084619065977\n",
      "probability 2 0.0004102482696008991\n",
      "loss2 -7.798748045916683\n",
      "probability 1 0.9947771352887782\n",
      "loss1 -0.005236551546242604\n",
      "0.051551746248454204\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    data = make_df(\"../../train.csv\")\n",
    "    y = data[\"Category\"]\n",
    "    test_data = make_df(\"../../test.csv\")\n",
    "    y_test = test_data[\"Category\"]       \n",
    "    vector, vector_test = vectorize(data, test_data)\n",
    " #   make_classifier(vector, data, vector_test)\n",
    "\n",
    "    cels = []\n",
    "    num_nods = [5, 20, 40]\n",
    "    for num in num_nods:\n",
    "        probs, clf = make_classifier(vector, y, vector_test, num)\n",
    "        cel = calc_cels(probs, y, clf)\n",
    "        cels.append(cel)\n",
    "\n",
    "    plt.plot(num_nods, cels, marker = \"*\", color = \"#F543BA\", markersize = 10)\n",
    "    plt.title(\"Cross entropy loss\")\n",
    "    plt.show()\n",
    "\n",
    "    ms = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    test_f1s = []\n",
    "    train_f1s = []\n",
    "\n",
    "    for m in ms:\n",
    "        train_f1, test_f1 = train_on_m(y, vector, vector_test, m, y_test)\n",
    "        test_f1s.append(test_f1)\n",
    "        train_f1s.append(train_f1)\n",
    "\n",
    "    \n",
    "    plt.plot(ms, test_f1s, marker = \"o\", color = \"#BA52FF\", markersize = 7)\n",
    "    plt.title(\"Test f1s\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(ms, train_f1s, marker = \"x\", color = \"#F431CB\", markersize = 8)\n",
    "    plt.title(\"Train f1s\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def vectorize(data, test_data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(data[\"Text\"])\n",
    "    print(f'vector vocabulary - {vectorizer.vocabulary}\\n')\n",
    "\n",
    "    vector = vectorizer.transform(data[\"Text\"])\n",
    "    test_vector = vectorizer.transform(test_data[\"Text\"])\n",
    "    \n",
    "    print(f'features\\n {vectorizer.get_feature_names_out()}\\n')\n",
    "\n",
    "    print(f'vector shape: {vector.shape}\\n')\n",
    "    print(f'article vector\\n {vector.toarray()}')\n",
    "\n",
    "    return vector, test_vector\n",
    "\n",
    "def make_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def calc_cels(probs, train_y, clf):\n",
    "    total = 0\n",
    "    print(probs)\n",
    "    print(clf.classes_)\n",
    "    print(train_y)\n",
    "    for ind in range(len(probs)):\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        if train_y[ind] == \"tech\":\n",
    "            loss1 = math.log(probs[ind][1])\n",
    "            print(\"probability 1\", probs[ind][1])\n",
    "            print(\"loss1\", loss1)\n",
    "        else:\n",
    "            loss1 = 0\n",
    "        if train_y[ind] == \"entertainment\":\n",
    "            loss2 = math.log(probs[ind][0])\n",
    "            print(\"probability 2\", probs[ind][0])\n",
    "            print(\"loss2\", loss2)\n",
    "        else:\n",
    "            loss2 = 0\n",
    "        cel = - (loss1 + loss2)\n",
    "        total += cel\n",
    "\n",
    "    print(np.mean(clf.loss_curve_))\n",
    "\n",
    "    avg_cel = total / len(probs)\n",
    "\n",
    "    return avg_cel\n",
    "\n",
    "# passes in training xs, training ys, testing xs\n",
    "''' THIS IS THE CLASSIFIER FUNCTION YOU SHOULD MIRROR FOR YOUR MODEL FOR IT TO WORK WITH TASK 3\n",
    "    IGNORE num_nodes that is specific to the NN classifier. \n",
    "'''\n",
    "def make_classifier(vector, y, vector_test, num_nodes = 5): \n",
    "\n",
    "    clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = (num_nodes,)).fit(vector, y)\n",
    "\n",
    "\n",
    "    probs = clf.predict_proba(vector_test)\n",
    "\n",
    "    return probs, clf\n",
    "        \n",
    "def train_on_m(train_y, vector, vector_test, m, y_test):\n",
    "    \n",
    "    sub_vector = vector[0:round(vector.shape[0]*m)]\n",
    "    \n",
    "    probs, clf = make_classifier(sub_vector, train_y[0:round(len(train_y)*m)], vector_test)\n",
    "\n",
    "    preds_test = clf.predict(vector_test)\n",
    "\n",
    "    preds_train = clf.predict(sub_vector)\n",
    "\n",
    "    train_f1 = calc_f1(preds_train, train_y)\n",
    "    test_f1 = calc_f1(preds_test, y_test)\n",
    "\n",
    "    return train_f1, test_f1\n",
    "\n",
    "def calc_f1(preds, actual):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "# tech is positive\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == \"tech\" and actual[i] == \"tech\":\n",
    "            tp += 1\n",
    "        elif preds[i] == \"tech\" and actual[i] == \"entertainment\":\n",
    "            fp += 1\n",
    "        elif preds[i] == \"entertainment\" and actual[i] == \"entertainment\":\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2*((precision*recall) / (precision+recall))\n",
    "\n",
    "    return f1\n",
    "\n",
    "main()\n",
    "\n",
    "# hyperparams; #hidden layers, #neurons per layer, #activation function\n",
    "\n",
    "# adj initial weight, adj learning rate, adj # epoch,\n",
    "#adj # hidden units (1layer has x units)\n",
    "\n",
    "#act function relu\n",
    "#solver sgd\n",
    "#alpha leave default\n",
    "#learning_rate_init: set to 0.01\n",
    "#max_iter: 100 (#epochs)\n",
    "#\n",
    "\n",
    "# got a warning.warn from warnings which told us there was a warning about convergance, stopped training bc max iter = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639512b",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72002d5",
   "metadata": {},
   "source": [
    "(a) We explore how the size of the training data set affects the test and train accuracy. For each\n",
    "value of m in [0.1, 0.3, 0.5, 0.7, 0.9], train your classifier on the first m portion of the training\n",
    "examples (that is, use the data given by XTrain[0:mN] and yTrain[0:mN]). Please report two\n",
    "plots: (i) training and (ii) testing accuracy for each such value of m with the x-axis referring to m\n",
    "and the y-axis referring to the classification accuracy in 𝐹1 measure as shown below. In total,\n",
    "there should be four curves for training accuracy and four curves for testing accuracy. Explain\n",
    "the general trend of the two plots in terms of training and testing accuracy if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_m(train_y, vector, vector_test, m, y_test):\n",
    "    \n",
    "    sub_vector = vector[0:round(vector.shape[0]*m)]\n",
    "    \n",
    "    probs, clf = make_classifier(sub_vector, train_y[0:round(len(train_y)*m)], vector_test)\n",
    "\n",
    "    preds_test = clf.predict(vector_test)\n",
    "\n",
    "    preds_train = clf.predict(sub_vector)\n",
    "\n",
    "    train_f1 = calc_f1(preds_train, train_y)\n",
    "    test_f1 = calc_f1(preds_test, y_test)\n",
    "\n",
    "    return train_f1, test_f1\n",
    "\n",
    "def calc_f1(preds, actual):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "# tech is positive\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == \"tech\" and actual[i] == \"tech\":\n",
    "            tp += 1\n",
    "        elif preds[i] == \"tech\" and actual[i] == \"entertainment\":\n",
    "            fp += 1\n",
    "        elif preds[i] == \"entertainment\" and actual[i] == \"entertainment\":\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2*((precision*recall) / (precision+recall))\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8471a",
   "metadata": {},
   "source": [
    "(b) Let’s use 5-fold cross-validation to assess model performance. Investigate the impact of key\n",
    "hyperparameters of your choices for each classifier using a testing dataset. E.g., for SVM, the\n",
    "classification accuracy may be significantly affected by the kernels and hyperparameter\n",
    "combination. List hyperparameters for each classifier and demonstrate how these\n",
    "hyperparameters impact on the testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c523aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector vocabulary - None\n",
      "\n",
      "features\n",
      " ['00' '000' '000th' ... 'zooms' 'zooropa' 'zorro']\n",
      "\n",
      "vector shape: (428, 13518)\n",
      "\n",
      "article vector\n",
      " [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Scores for normal classifier: [1.         0.98837052 0.97674419 1.         0.97646733] with average 0.9883164075574096\n",
      "LEARNING RATE\n",
      "Score for learning rate 0.001: [1.         1.         0.95194508 0.78571429 0.95194508] with average 0.9379208891794704\n",
      "Score for learning rate 0.005: [1.         0.95058824 0.95058824 0.89903846 1.        ] with average 0.9600429864253395\n",
      "Score for learning rate 0.01: [1.         1.         0.95058824 0.89903846 1.        ] with average 0.9699253393665159\n",
      "Score for learning rate 0.05: [1.         0.95058824 1.         0.84444444 1.        ] with average 0.9590065359477125\n",
      "Score for learning rate 0.1: [1.         0.95058824 1.         0.78571429 1.        ] with average 0.9472605042016806\n",
      "Score for learning rate 0.5: [1.         1.         0.95194508 0.78571429 1.        ] with average 0.9475318731611637\n",
      "Score for learning rate 0.75: [1.         0.95194508 0.84444444 0.85176471 1.        ] with average 0.9296308460836661\n",
      "Score for learning rate 1: [1.         0.95058824 0.95194508 0.84444444 0.90454545] with average 0.93030464287511\n",
      "Score for learning rate 2: [0.37142857 0.95194508 0.95194508 0.36363636 0.95194508] with average 0.718180035067907\n",
      "Score for learning rate 5: [0.95206972 1.         0.95058824 0.84444444 0.53333333] with average 0.856087145969499\n",
      "MAX ITERATIONS\n",
      "Score for max iterations 5: [0.84827586 0.36363636 0.85583524 0.61111111 0.95058824] with average 0.7258893624770315\n",
      "Score for max iterations 50: [1.         0.95058824 0.80909091 0.78571429 1.        ] with average 0.9090786860198625\n",
      "Score for max iterations 100: [1.         0.95058824 0.95058824 0.89903846 1.        ] with average 0.9600429864253395\n",
      "Score for max iterations 200: [0.95206972 0.95058824 0.95058824 0.84444444 1.        ] with average 0.9395381263616558\n",
      "Score for max iterations 500: [1.         0.95058824 1.         0.84444444 1.        ] with average 0.9590065359477125\n",
      "Score for max iterations 1000: [0.95206972 0.95058824 1.         0.89903846 1.        ] with average 0.9603392827216357\n",
      "Score for max iterations 5000: [1.         0.95058824 1.         0.90277778 1.        ] with average 0.970673202614379\n",
      "ACTIVATION FUNCTION\n",
      "Score for activation function relu: [1.         0.95058824 1.         0.89903846 1.        ] with average 0.9699253393665159\n",
      "Score for activation function identity: [1.         0.95058824 1.         0.84444444 1.        ] with average 0.9590065359477125\n",
      "Score for activation function logistic: [1.         0.95058824 1.         0.84444444 1.        ] with average 0.9590065359477125\n",
      "Score for activation function tanh: [1.         0.95058824 1.         0.89903846 1.        ] with average 0.9699253393665159\n",
      "HIDDEN LAYERS\n",
      "Score for number of layers =  1: [1.         0.95058824 1.         0.89903846 1.        ] with average 0.9699253393665159\n",
      "Score for number of layers =  2: [0.95206972 0.95058824 1.         0.84444444 1.        ] with average 0.9494204793028324\n",
      "Score for number of layers =  3: [0.95206972 0.84444444 0.95194508 0.78571429 0.36363636] with average 0.7795619781324452\n",
      "Score for number of layers =  4: [1.         0.95058824 0.89903846 0.36363636 1.        ] with average 0.8426526120937886\n",
      "Score for number of layers =  5: [1.         0.84444444 0.80909091 0.78571429 0.36363636] with average 0.7605772005772006\n",
      "Score for number of layers =  10: [0.37142857 0.36363636 0.36363636 0.36363636 0.36363636] with average 0.3651948051948052\n",
      "Score for number of layers =  20: [0.37142857 0.36363636 0.36363636 0.36363636 0.36363636] with average 0.3651948051948052\n",
      "Score for number of layers =  40: [0.37142857 0.36363636 0.36363636 0.36363636 0.36363636] with average 0.3651948051948052\n",
      "Score for Max iterations = 100 learning rate = 0.001: [0.37142857 0.53333333 0.90277778 0.72148541 0.36363636] with average 0.578532291463326\n",
      "Score for Max iterations = 100 learning rate = 0.005: [0.37142857 0.95058824 0.65       0.84444444 0.80909091] with average 0.7251104320516085\n",
      "Score for Max iterations = 100 learning rate = 0.01: [0.95206972 0.95058824 1.         0.84444444 1.        ] with average 0.9494204793028324\n",
      "Score for Max iterations = 100 learning rate = 0.05: [0.95206972 0.89903846 1.         0.78571429 0.85714286] with average 0.8987930642342408\n",
      "Score for Max iterations = 100 learning rate = 0.1: [1.         0.95058824 0.95194508 0.90277778 1.        ] with average 0.9610622186326857\n",
      "Score for Max iterations = 200 learning rate = 0.001: [1.         0.70833333 0.95058824 0.90454545 0.95194508] with average 0.9030824206528877\n",
      "Score for Max iterations = 200 learning rate = 0.005: [1.         0.78571429 0.78571429 0.89903846 0.89903846] with average 0.8739010989010989\n",
      "Score for Max iterations = 200 learning rate = 0.01: [1.         0.95058824 1.         0.78571429 0.85714286] with average 0.9186890756302521\n",
      "Score for Max iterations = 200 learning rate = 0.05: [1.         0.95058824 0.89903846 0.90277778 1.        ] with average 0.9504808949220713\n",
      "Score for Max iterations = 200 learning rate = 0.1: [0.95206972 0.95058824 1.         0.78571429 0.95194508] with average 0.928063463575107\n",
      "Score for Max iterations = 500 learning rate = 0.001: [1.         1.         1.         0.95058824 0.78571429] with average 0.9472605042016807\n",
      "Score for Max iterations = 500 learning rate = 0.005: [1.         0.72148541 0.72148541 0.89903846 0.89903846] with average 0.8482095490716179\n",
      "Score for Max iterations = 500 learning rate = 0.01: [0.95206972 0.89903846 1.         0.90277778 1.        ] with average 0.9507771912183678\n",
      "Score for Max iterations = 500 learning rate = 0.05: [1.         0.95058824 1.         0.84444444 0.85714286] with average 0.9304351073762838\n",
      "Score for Max iterations = 500 learning rate = 0.1: [0.95206972 0.95058824 0.95194508 0.90277778 0.85714286] with average 0.922904733416377\n",
      "Score for Max iterations = 1000 learning rate = 0.001: [1.         0.72148541 1.         0.84444444 1.        ] with average 0.9131859711170055\n",
      "Score for Max iterations = 1000 learning rate = 0.005: [0.95206972 0.84444444 1.         0.89903846 1.        ] with average 0.9391105245517011\n",
      "Score for Max iterations = 1000 learning rate = 0.01: [1.         0.95058824 0.95058824 0.84444444 0.89903846] with average 0.9289318753142283\n",
      "Score for Max iterations = 1000 learning rate = 0.05: [0.95206972 0.95058824 0.90454545 0.78571429 1.        ] with average 0.9185835384658914\n",
      "Score for Max iterations = 1000 learning rate = 0.1: [0.95206972 0.95058824 0.89903846 0.95194508 1.        ] with average 0.9507282987399425\n",
      "Score for Max iterations = 5000 learning rate = 0.001: [0.95206972 0.72148541 0.95058824 0.90454545 0.84444444] with average 0.8746266524400397\n",
      "Score for Max iterations = 5000 learning rate = 0.005: [1.         0.95058824 0.90454545 0.89903846 0.84444444] with average 0.9197233191644957\n",
      "Score for Max iterations = 5000 learning rate = 0.01: [1.         0.95058824 1.         0.89903846 1.        ] with average 0.9699253393665159\n",
      "Score for Max iterations = 5000 learning rate = 0.05: [0.95206972 0.95058824 0.84444444 0.89903846 0.90277778] with average 0.90978372716608\n",
      "Score for Max iterations = 5000 learning rate = 0.1: [1.         0.95058824 1.         0.84444444 1.        ] with average 0.9590065359477125\n"
     ]
    }
   ],
   "source": [
    "#use 5-fold CV to assess performance, experiment w diff hyperparams\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def vectorize(data, test_data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(data[\"Text\"])\n",
    "    print(f'vector vocabulary - {vectorizer.vocabulary}\\n')\n",
    "\n",
    "    vector = vectorizer.transform(data[\"Text\"])\n",
    "    test_vector = vectorizer.transform(test_data[\"Text\"])\n",
    "    \n",
    "    print(f'features\\n {vectorizer.get_feature_names_out()}\\n')\n",
    "\n",
    "    print(f'vector shape: {vector.shape}\\n')\n",
    "    print(f'article vector\\n {vector.toarray()}')\n",
    "\n",
    "    return vector, test_vector\n",
    "\n",
    "def make_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    data = make_df(\"../../train.csv\")\n",
    "    y = data[\"Category\"]\n",
    "    test_data = make_df(\"../../test.csv\")\n",
    "    y_test = test_data[\"Category\"]       \n",
    "    vector, vector_test = vectorize(data, test_data)\n",
    "    probs, model = make_classifier(vector, y, vector_test)\n",
    "\n",
    "    cross_validate(model, vector, y, vector_test, y_test)\n",
    "\n",
    "    # passes in training xs, training ys, testing xs\n",
    "def make_classifier(vector, y, vector_test, num_nodes = 5): # discuss num nodes in report\n",
    "\n",
    "    clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = (num_nodes,)).fit(vector, y)\n",
    "\n",
    "\n",
    "    probs = clf.predict_proba(vector_test)\n",
    "\n",
    "    return probs, clf\n",
    "\n",
    "def cross_validate(clf, train_descriptions, train_y, test_descriptions, test_y):\n",
    "    # use kfold validation (k = 5).\n",
    "    # hyperparameters that we used:\n",
    "    \n",
    "    scores = cross_val_score(clf, train_descriptions, train_y, cv=5, scoring=\"f1_macro\")\n",
    "\n",
    "    print(\"Scores for normal classifier:\", scores, \"with average\", str(sum(scores) / len(scores)))\n",
    "\n",
    "    print(\"LEARNING RATE\")\n",
    "    learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.75, 1, 2, 5]\n",
    "    for learning_rate in learning_rates:\n",
    "        # retrain clf\n",
    "        clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = learning_rate,\n",
    "                        max_iter = 100, hidden_layer_sizes = (5,)).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"learning rate\", learning_rate)\n",
    "\n",
    "    print(\"MAX ITERATIONS\")\n",
    "    max_iter_values = [5, 50, 100, 200, 500, 1000, 5000]\n",
    "    for max_iter_val in max_iter_values:\n",
    "        # retrain clf\n",
    "        clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = max_iter_val, hidden_layer_sizes = (5,)).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"max iterations\", max_iter_val)\n",
    "\n",
    "    print(\"ACTIVATION FUNCTION\")\n",
    "    activation_functions = [\"relu\", \"identity\", \"logistic\", \"tanh\"]\n",
    "    for function in activation_functions:\n",
    "        # retrain clf\n",
    "        clf = MLPClassifier(activation = function, solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = (5,)).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"activation function\", function)\n",
    "\n",
    "    print(\"HIDDEN LAYERS\")\n",
    "    num_layers = [1, 2, 3, 4, 5, 10, 20, 40]\n",
    "    for num in num_layers:\n",
    "        # retrain clf\n",
    "        sizes = (5,) * num\n",
    "        clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = sizes).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"number of layers = \", num)\n",
    "\n",
    "\n",
    "    # EPOCHS & LEARNING RATE TOGETHER\n",
    "    # learning rate of 0.5 was best for any epoch size\n",
    "    # epoch of size 500 & 1000 with 0.5 learning rate tied best w score of 0.9603\n",
    "    # landed on epoch size 500 for computation sake\n",
    "\n",
    "    # taking subset of the better epochs and learning rates\n",
    "    max_iter_values = [100, 200, 500, 1000, 5000]\n",
    "    learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    for iter_val in max_iter_values:\n",
    "        for learning_rate in learning_rates:\n",
    "        # retrain clf for each combo of learning rate and max iter\n",
    "            clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = learning_rate,\n",
    "                            max_iter = iter_val, hidden_layer_sizes = 2).fit(train_descriptions, train_y)\n",
    "            get_scores(clf, test_descriptions, test_y, f\"Max iterations = {iter_val}\", f\"learning rate = {learning_rate}\") # change this text\n",
    "\n",
    "\n",
    "def get_scores(clf, test_descriptions, test_y, hyperparam, value):\n",
    "        scores = cross_val_score(clf, test_descriptions, test_y, cv=5, scoring=\"f1_macro\")\n",
    "        avg = sum(scores) / len(scores)\n",
    "        print(f\"Score for {hyperparam} {value}:\", scores, \"with average\", str(avg))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42106ed3",
   "metadata": {},
   "source": [
    "Effects of different hyperparameters on the F1 score on the test data:\n",
    "_Note that all other variables were constant wrt their initial settings from 2d) when constructed._\n",
    "**Learning Rate** - This is adjusted by changing the learning_rate parameter of the MLPClassifier. We used values of 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.75, 1, 2, and 5 as test learning rates. For very small learning rates eg 0.001, the accuracy on the test set was fairly low, sitting at about 90% across muliple reruns. Slight increases in learning rate to 0.01 and 0.05 showed increased performance on the unseen test set, with further increases at and beyond ~0.5 again decreasing the test accuracy.\n",
    "\n",
    "Generally, for very small learning rates, the amount of time required for convergence is much higher. It could be that with the number of epochs used in the default case (100), a learning rate of 0.001 was too low for convergence to be reached as each iteration takes a very small step, and thus the model is not fully developed at the point execution is terminated. Conversely, for larger learning rates (start to see the decrease in accuracy at0.1, but particularly those above ~0.5), we see a further decrease in accuracy. This could be due to the jumping behaviour that is often seen for large learning rates, where relative minima are completely overshot, and we never encounter convergence. Therefore, it appears that for this model, learning rates beyond about 0.5 are too large.\n",
    "Therefore, for this model, it appears the best learning rate to use is somewhere between 0.005 and 0.05, depending on whether we have more epochs than the baseline classifier (thus a smaller learning rate) or less (thus need a slightly larger learning rate).\n",
    "\n",
    "**Number of Epochs** - this is adjusted by changing the value of max_iter passed into the MLPClassifier. The values we tried were 5, 50, 100, 200, 500, 1000, and 5000.\n",
    "For low epoch numbers (5 and 50), we recieved convergence warnings when running our models, saying that the number of epochs was too low for MLPClassifier to have converged. Additionally, for the lower 5 epoch run, the accuracy was quite clearly lower compared to higher epoch counts. This suggests that for these low epoch counts, we are not reaching an optimal classifier before execution is terminated.\n",
    "\n",
    "For all runs of 100 epochs or higher, the accuracy seems fairly consistent. This suggests that with the baseline settings from 2d), 100 epochs is sufficient to have a well trained model. As the number of epochs increases, so does computation expense, so that is also an important consideration to make to ensure that the model will terminate in good time. It is also worth noting that the default value for this in MLPClassifier is 200 - which is twice as large as our default. \n",
    "\n",
    "For this model, any epoch count greater than 100 appears to be sufficient - this should be increased higher depending on the other hyperparameters we set.\n",
    "\n",
    "**Activation Function** - Scikit Learn has an activation function parameter, which sets the activation function of the hidden layers. The options were \"relu\", \"identity\", \"logistic\" (ie sigmoid), and \"tanh\". THe initial classifier we developed used the RelU function.\n",
    "Running this multiple times, there was some variation, but all four models stayed relatively similar. For this reason, it makes most sense to stick with Relu, which is relatively fast to train (so should stay high performing regardless of number of epochs). Note also that scikit learn by default uses sigmoid on the output layer.\n",
    "\n",
    "**Number of Hidden Layers** - This was the final parameter we decided to adjust, since the number of nodes was already adjusted for 2d). We used values of 1, 2, 3, 4, 5, 10, 20, and 40.\n",
    "The baseline classifier used 1 hidden layer, which is as low as possible, but had a decent accuracy score. As the number of hidden layers increased to 3 and above, the accuracy massively decreased. This could be due to overfitting on the training dataset, as the increased number of hidden layers makes the model more sensitive to noise and outliers in the training set. Also, as the number of hidden layers increases, the model is more susceptible to vanishing (very small) and exploding (very large) gradients during the back propogation algorithm, making weights disproportionate.\n",
    "\n",
    "Since the number of hidden layers has nothing to do wth the number of epochs or learning rate, we have decided to set it to 2, to help further train the model slightly without risking overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
