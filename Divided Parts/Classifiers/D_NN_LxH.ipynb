{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../../train.csv\")\n",
    "X = df[\"Text\"].values\n",
    "y = df[\"Category\"].values\n",
    "m = 0.9 #proportion of data for training vs validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=m, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d1cec",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae98f0",
   "metadata": {},
   "source": [
    "(d) NN. Consider a neural network with the following hyperparameters: the initial weights\n",
    "uniformly drawn in range [0,0.1] with learning rate 0.01.\n",
    "\n",
    "    â— Train a single hidden layer neural network using the hyperparameters on the training dataset, except for the number of hidden units (x) which should vary among 5, 20, and 40. Run the optimization for 100 epochs each time. Namely, the input layer consists of n features x = [x1, ..., xn]^T , the hidden layer has x nodes z = [z1, ..., zx]^T , and the output layer is a probability distribution y = [y1, y2]^T over two classes.\n",
    "\n",
    "    â— Plot the average training cross-entropy loss as shown below on the y-axis versus the number of hidden units on the x-axis. Explain the effect of numbers of hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ba117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SORRY THIS IS A MESS WE WILL CLEAN IT UP LATER DO NOT USE THIS CLASSIFIER IT IS BROKEN \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    data = make_df(\"train.csv\")\n",
    "    y = data[\"Category\"]\n",
    "    test_data = make_df(\"test.csv\")\n",
    "    y_test = test_data[\"Category\"]       \n",
    "    vector, vector_test = vectorize(data, test_data)\n",
    " #   make_classifier(vector, data, vector_test)\n",
    "\n",
    "    cels = []\n",
    "    num_nods = [5, 20, 40]\n",
    "    for num in num_nods:\n",
    "        probs, clf = make_classifier(vector, y, vector_test, num)\n",
    "        cel = calc_cels(probs)\n",
    "        cels.append(cel)\n",
    "\n",
    "    plt.plot(num_nods, cels, marker = \"*\", color = \"#F543BA\", markersize = 10)\n",
    "    plt.title(\"Cross entropy loss\")\n",
    "    plt.show()\n",
    "\n",
    "    ms = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    test_f1s = []\n",
    "    train_f1s = []\n",
    "\n",
    "    for m in ms:\n",
    "        train_f1, test_f1 = train_on_m(y, vector, vector_test, m, y_test)\n",
    "        test_f1s.append(test_f1)\n",
    "        train_f1s.append(train_f1)\n",
    "\n",
    "    \n",
    "    plt.plot(ms, test_f1s, marker = \"o\", color = \"#BA52FF\", markersize = 7)\n",
    "    plt.title(\"Test f1s\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(ms, train_f1s, marker = \"x\", color = \"#F431CB\", markersize = 8)\n",
    "    plt.title(\"Train f1s\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def vectorize(data, test_data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(data[\"Text\"])\n",
    "    print(f'vector vocabulary - {vectorizer.vocabulary}\\n')\n",
    "\n",
    "    vector = vectorizer.transform(data[\"Text\"])\n",
    "    test_vector = vectorizer.transform(test_data[\"Text\"])\n",
    "    \n",
    "    print(f'features\\n {vectorizer.get_feature_names_out()}\\n')\n",
    "\n",
    "    print(f'vector shape: {vector.shape}\\n')\n",
    "    print(f'article vector\\n {vector.toarray()}')\n",
    "\n",
    "    return vector, test_vector\n",
    "\n",
    "def make_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def calc_cels(probs):\n",
    "    total = 0\n",
    "\n",
    "    for pair in probs:\n",
    "        loss1 = pair[0] * math.log(pair[0])\n",
    "        loss2 = pair[1] * math.log(pair[1])\n",
    "        cel = - (loss1 + loss2)\n",
    "        total += cel\n",
    "\n",
    "    avg_cel = total / len(probs)\n",
    "\n",
    "    return avg_cel\n",
    "\n",
    "\n",
    "# passes in training xs, training ys, testing xs\n",
    "''' THIS IS THE CLASSIFIER FUNCTION YOU SHOULD MIRROR FOR YOUR MODEL FOR IT TO WORK WITH TASK 3\n",
    "    IGNORE num_nodes that is specific to the NN classifier. \n",
    "'''\n",
    "def make_classifier(vector, y, vector_test, num_nodes = 5): \n",
    "\n",
    "    clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = (num_nodes,)).fit(vector, y)\n",
    "\n",
    "\n",
    "    probs = clf.predict_proba(vector_test)\n",
    "\n",
    "    return probs, clf\n",
    "        \n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# hyperparams; #hidden layers, #neurons per layer, #activation function\n",
    "\n",
    "# adj initial weight, adj learning rate, adj # epoch,\n",
    "#adj # hidden units (1layer has x units)\n",
    "\n",
    "\n",
    "\n",
    "#act function relu\n",
    "#solver sgd\n",
    "#alpha leave default\n",
    "#learning_rate_init: set to 0.01\n",
    "#max_iter: 100 (#epochs)\n",
    "#\n",
    "\n",
    "# got a warning.warn from warnings which told us there was a warning about convergance, stopped training bc max iter = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639512b",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72002d5",
   "metadata": {},
   "source": [
    "(a) We explore how the size of the training data set affects the test and train accuracy. For each\n",
    "value of m in [0.1, 0.3, 0.5, 0.7, 0.9], train your classifier on the first m portion of the training\n",
    "examples (that is, use the data given by XTrain[0:mN] and yTrain[0:mN]). Please report two\n",
    "plots: (i) training and (ii) testing accuracy for each such value of m with the x-axis referring to m\n",
    "and the y-axis referring to the classification accuracy in ð¹1 measure as shown below. In total,\n",
    "there should be four curves for training accuracy and four curves for testing accuracy. Explain\n",
    "the general trend of the two plots in terms of training and testing accuracy if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_m(train_y, vector, vector_test, m, y_test):\n",
    "    \n",
    "    sub_vector = vector[0:round(vector.shape[0]*m)]\n",
    "    \n",
    "    probs, clf = make_classifier(sub_vector, train_y[0:round(len(train_y)*m)], vector_test)\n",
    "\n",
    "    preds_test = clf.predict(vector_test)\n",
    "\n",
    "    preds_train = clf.predict(sub_vector)\n",
    "\n",
    "    train_f1 = calc_f1(preds_train, train_y)\n",
    "    test_f1 = calc_f1(preds_test, y_test)\n",
    "\n",
    "    return train_f1, test_f1\n",
    "\n",
    "def calc_f1(preds, actual):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "# tech is positive\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == \"tech\" and actual[i] == \"tech\":\n",
    "            tp += 1\n",
    "        elif preds[i] == \"tech\" and actual[i] == \"entertainment\":\n",
    "            fp += 1\n",
    "        elif preds[i] == \"entertainment\" and actual[i] == \"entertainment\":\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2*((precision*recall) / (precision+recall))\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8471a",
   "metadata": {},
   "source": [
    "(b) Letâ€™s use 5-fold cross-validation to assess model performance. Investigate the impact of key\n",
    "hyperparameters of your choices for each classifier using a testing dataset. E.g., for SVM, the\n",
    "classification accuracy may be significantly affected by the kernels and hyperparameter\n",
    "combination. List hyperparameters for each classifier and demonstrate how these\n",
    "hyperparameters impact on the testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c523aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector vocabulary - None\n",
      "\n",
      "features\n",
      " ['00' '000' '000th' ... 'zooms' 'zooropa' 'zorro']\n",
      "\n",
      "vector shape: (428, 13518)\n",
      "\n",
      "article vector\n",
      " [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'make_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m         avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(scores)\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhyperparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith average\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(avg))\n\u001b[1;32m--> 108\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[5], line 40\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]       \n\u001b[0;32m     39\u001b[0m vector, vector_test \u001b[38;5;241m=\u001b[39m vectorize(data, test_data)\n\u001b[1;32m---> 40\u001b[0m probs, model \u001b[38;5;241m=\u001b[39m make_classifier(vector, y, vector_test)\n\u001b[0;32m     42\u001b[0m cross_validate(model, vector, y, vector_test, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "#use 5-fold CV to assess performance, experiment w diff hyperparams\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def vectorize(data, test_data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(data[\"Text\"])\n",
    "    print(f'vector vocabulary - {vectorizer.vocabulary}\\n')\n",
    "\n",
    "    vector = vectorizer.transform(data[\"Text\"])\n",
    "    test_vector = vectorizer.transform(test_data[\"Text\"])\n",
    "    \n",
    "    print(f'features\\n {vectorizer.get_feature_names_out()}\\n')\n",
    "\n",
    "    print(f'vector shape: {vector.shape}\\n')\n",
    "    print(f'article vector\\n {vector.toarray()}')\n",
    "\n",
    "    return vector, test_vector\n",
    "\n",
    "def make_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    data = make_df(\"../../train.csv\")\n",
    "    y = data[\"Category\"]\n",
    "    test_data = make_df(\"../../test.csv\")\n",
    "    y_test = test_data[\"Category\"]       \n",
    "    vector, vector_test = vectorize(data, test_data)\n",
    "    probs, model = make_classifier(vector, y, vector_test)\n",
    "\n",
    "    cross_validate(model, vector, y, vector_test, y_test)\n",
    "\n",
    "    # passes in training xs, training ys, testing xs\n",
    "def make_classifier(vector, y, vector_test, num_nodes = 5): # discuss num nodes in report\n",
    "\n",
    "    clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = (num_nodes,)).fit(vector, y)\n",
    "\n",
    "\n",
    "    probs = clf.predict_proba(vector_test)\n",
    "\n",
    "    return probs, clf\n",
    "\n",
    "def cross_validate(clf, train_descriptions, train_y, test_descriptions, test_y):\n",
    "    # use kfold validation (k = 5).\n",
    "    # hyperparameters that we used:\n",
    "    \n",
    "    scores = cross_val_score(clf, train_descriptions, train_y, cv=5, scoring=\"f1_macro\")\n",
    "\n",
    "    print(\"Scores for normal classifier:\", scores)\n",
    "\n",
    "    # LEARNING RATE\n",
    "    # very low learning rate had bad accuracy suggesting that it does not converge to minima with that epoch count\n",
    "    # marginal change, but incr learning rate caused slightly lower avg perf, so better to keep small (not too small for computations sake.\n",
    "    print(\"LEARNING RATE\")\n",
    "    learning_rates = [0.001, 0.01, 0.05, 0.1, 0.5, 0.75, 1, 2, 5]\n",
    "    for learning_rate in learning_rates:\n",
    "        # retrain clf\n",
    "        clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = learning_rate,\n",
    "                        max_iter = 100, hidden_layer_sizes = (5,)).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"learning rate\", learning_rate)\n",
    "\n",
    "    # MAX ITER\n",
    "    # for very low values of max_iter_val, we get a convergence warning\n",
    "    # always for 5 and 50, sometimes for 100, never for bigger than that\n",
    "    # really large epoch values don't give much noticeable change to the accuracy\n",
    "    # therefore suggesting there has been convergence before that many epochs and we are running unnecessarily\n",
    "    # so we will use the default from scikit learn of 200 epochs.\n",
    "    print(\"MAX ITERATIONS\")\n",
    "    max_iter_values = [5, 50, 100, 200, 500, 1000, 5000]\n",
    "    for max_iter_val in max_iter_values:\n",
    "        # retrain clf\n",
    "        clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = max_iter_val, hidden_layer_sizes = (5,)).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"max iterations\", max_iter_val)\n",
    "\n",
    "    # ACTIVATION FUNCTION\n",
    "    # doesn't seem like there's much change beyond natural variation\n",
    "    # all between 97 and 99 which we have seen similar scores from relu alone\n",
    "    # might be worth looking at sigmoid vs relu for this context to justify continuing with relu\n",
    "    print(\"ACTIVATION FUNCTION\")\n",
    "    activation_functions = [\"relu\", \"identity\", \"logistic\", \"tanh\"]\n",
    "    for function in activation_functions:\n",
    "        # retrain clf\n",
    "        clf = MLPClassifier(activation = function, solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = (5,)).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"activation function\", function)\n",
    "\n",
    "    # HIDDEN LAYERS\n",
    "    # increasing number of hidden layers for this decreased accuracy, and also gave us warning from warnings.warn convergence warning\n",
    "    # this meant that the optimal number of hidden layers for 100 epoch is 1\n",
    "    # but may need fine tuning alongside other epoch numbers\n",
    "    print(\"HIDDEN LAYERS\")\n",
    "    num_layers = [1, 2, 3, 4, 5, 10, 20, 40]\n",
    "    for num in num_layers:\n",
    "        # retrain clf\n",
    "        sizes = (5,) * num\n",
    "        clf = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01,\n",
    "                        max_iter = 100, hidden_layer_sizes = sizes).fit(train_descriptions, train_y)\n",
    "        get_scores(clf, test_descriptions, test_y, \"number of layers = \", num)\n",
    "\n",
    "\n",
    "def get_scores(clf, test_descriptions, test_y, hyperparam, value):\n",
    "        scores = cross_val_score(clf, test_descriptions, test_y, cv=5, scoring=\"f1_macro\")\n",
    "        avg = sum(scores) / len(scores)\n",
    "        print(f\"Score for {hyperparam} {value}:\", scores, \"with average\", str(avg))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
